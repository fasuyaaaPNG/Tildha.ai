{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1_gX30wZH6O79Qcpg0VKuhNTaFeQrbOYg",
      "authorship_tag": "ABX9TyMu6TMMpj0RgoyRTDYCl9+U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fasuyaaaPNG/Tildha.ai/blob/main/Tildha_ai_Release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependensi"
      ],
      "metadata": {
        "id": "RkpSFxn2zVZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8oxSrx1zFlU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install ffmpeg-python\n",
        "!pip install assemblyai\n",
        "!pip install PyAudio\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts\n",
        "!pip install -q streamlit\n",
        "!npm install localtunnel\n",
        "!pip install streamlit-audiorecorder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart kernel"
      ],
      "metadata": {
        "id": "kzxUWDAazUON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quit()"
      ],
      "metadata": {
        "id": "knYr9ULHzcNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download 2 photos for user profile and AI\n",
        "\n",
        "user.svg: https://drive.google.com/file/d/1zUlHX0q3OLSNQWdMH403vvjYLirD4Tip/view?usp=drive_link\n",
        "\n",
        "logo.svg https://drive.google.com/file/d/1NWJeFny726e5ol7XlEAexnFiCoUhdd5D/view?usp=drive_link\n",
        "\n",
        "\n",
        "**Important note: Before running the code \"Tildha Release v1.0\", make sure you have uploaded the 2 svg files above to the files folder on the left.**\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC4AAAA6CAYAAADP/mu6AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABfUlEQVRoge3avUrDUBjG8SeJrbUKbUColEYwTiIqDkq8CgWdXRyKgoP34VAQwV3cvQihDoogOKUqaAt+I/WTNE0cxKm26ckJbwm8/7E5yflx6ElKiWJZlo8YpvYaEDaGU8dw6hhOHcOpU+620j4ALJWne20RKrYrznDqGE4dw6ljOHV9IoNnMu/YHL/FcH/j3+Pb9iiOnrKRwIISWvF1s9oWDQDFsRr0pCuN6iahFR9JOQCA1ZPJlmPL+Qcs5h+xYVZRso2O1/nyNHiS/y0Iwf+qN7SWz/ZvcpjV3zCn13Ewf9Hx/M+mip2KgfJLJsz0ACLcnK6vomQbcH0lcGxa81A0a1LzhVrxdl19DGDleCpw3OHCObIJub0Q29shw6ljOHUMpy628FAPoEGtGbVDOCH4/XcSuZQT+Fukm56dhNT5Ql+VveuC9ITAL3r3siB1DaEVP3sdwtrphNSEURXbzclw6hhOHcOpYzh1sYUr/L4KcQynjuHUMZw6hlP3A4gVTB6jD9w8AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "V0IhzOhp-GST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tildha Release v1.0"
      ],
      "metadata": {
        "id": "lkhUlNRlzsIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import streamlit as st\n",
        "from audiorecorder import audiorecorder\n",
        "from scipy.io.wavfile import write as wav_write\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "if 'conversation' not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "\n",
        "# def update_context(key, value):\n",
        "#     global_context[key] = value\n",
        "\n",
        "# def get_context(key):\n",
        "#     return global_context.get(key, None)\n",
        "\n",
        "# def process_input(user_input):\n",
        "#     last_input = get_context(\"last_user_input\")\n",
        "#     if last_input:\n",
        "#         user_input = f\"Previously, you said: {last_input}. Now, you say: {user_input}\"\n",
        "\n",
        "#     update_context(\"last_user_input\", user_input)\n",
        "#     return user_input\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  st.components.v1.html(AUDIO_HTML)\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return st.session_state.get(\"audio\", None)\n",
        "\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return AutoModelForCausalLM.from_pretrained(\n",
        "        \"Lvyn/AI-Tildha-Merged\",\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        "    )\n",
        "\n",
        "# Load the model\n",
        "model = load_model()\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(text):\n",
        "    bahasa = \"en\"\n",
        "    file = gTTS(text = text, lang=bahasa)\n",
        "    file.save(\"speech.wav\")\n",
        "\n",
        "    with open(\"speech.wav\", 'rb') as f :\n",
        "      audio = f.read()\n",
        "\n",
        "    return audio\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  return audio\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "    if prompt := st.chat_input(\"Ask Tildha\"):\n",
        "        st.chat_message('User', avatar=\"/content/user.svg\").markdown(prompt)\n",
        "        st.session_state.messages.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": prompt})\n",
        "        with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "            response = generate_response(prompt)\n",
        "            lang = detect_lang(prompt)\n",
        "            response = translate(lang, response)\n",
        "            responseTildha = f\"Tildha: {response}\"\n",
        "            st.markdown(responseTildha)\n",
        "        st.session_state.messages.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responseTildha})\n",
        "\n",
        "\n",
        "def text_to_speech():\n",
        "    if \"messagesTS\" not in st.session_state:\n",
        "        st.session_state.messagesTS = []\n",
        "\n",
        "    for message in st.session_state.messagesTS:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            if message[\"role\"] == \"User\":\n",
        "                st.markdown(message[\"content\"])\n",
        "            elif message[\"role\"] == \"Tildha\":\n",
        "                if message[\"content\"] != \"Audio response\":\n",
        "                    st.markdown(message[\"content\"])\n",
        "                    audio_file = generate_speech(message[\"content\"])\n",
        "                    st.audio(audio_file, format='audio/wav', autoplay=False)\n",
        "\n",
        "    if prompt := st.chat_input(\"Ask Tildha\"):\n",
        "        st.chat_message('User', avatar=\"/content/user.svg\").markdown(prompt)\n",
        "        st.session_state.messagesTS.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": prompt})\n",
        "\n",
        "        with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "            response = generate_response(prompt)\n",
        "            id_lang = detect_lang(prompt)\n",
        "            responses = translate(id_lang, response)\n",
        "\n",
        "            if id_lang == \"indonesian\":\n",
        "                audioFile = generate_indonesian_speech(responses)\n",
        "            else:\n",
        "                audioFile = generate_speech(responses)\n",
        "\n",
        "            st.session_state.messagesTS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responses})\n",
        "            st.markdown(responses)\n",
        "            st.audio(audioFile, format='audio/wav', autoplay=True)\n",
        "\n",
        "        # st.session_state.messagesTS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": \"Audio response\"})\n",
        "\n",
        "\n",
        "def speech_to_text():\n",
        "    audio_file_path = \"./output.wav\"\n",
        "    try:\n",
        "        if os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "    if \"messagesST\" not in st.session_state:\n",
        "        st.session_state.messagesST = []\n",
        "    for message in st.session_state.messagesST:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "    st.divider()\n",
        "\n",
        "    option = st.selectbox(\n",
        "        \"Select language\",\n",
        "        [\"Indonesian\", \"English\"]\n",
        "    )\n",
        "\n",
        "    audio = audiorecorder(\"Click to record\", \"Click to stop recording\")\n",
        "\n",
        "    if len(audio) > 0:\n",
        "        try:\n",
        "            audio.export(audio_file_path, format=\"wav\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error saving audio file: {e}\")\n",
        "            return\n",
        "\n",
        "    speech = \"\"\n",
        "\n",
        "    if os.path.exists(audio_file_path):\n",
        "        if option == \"Indonesian\":\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "        elif option == \"English\":\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "    else:\n",
        "        st.error(\"Please select language selection.\")\n",
        "        return\n",
        "\n",
        "    if not speech:\n",
        "        st.error(\"No speech generated. Please check the audio input or language selection.\")\n",
        "        return\n",
        "\n",
        "    st.chat_message('User', avatar=\"/content/user.svg\").markdown(speech)\n",
        "    st.session_state.messagesST.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": speech})\n",
        "\n",
        "    with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "        response = generate_response(speech)\n",
        "        id_lang = detect_lang(speech)\n",
        "        responses = translate(id_lang, response)\n",
        "        responseTildha = f\"Tildha: {responses}\"\n",
        "        st.markdown(responseTildha)\n",
        "\n",
        "    st.session_state.messagesST.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responseTildha})\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    time.sleep(1)\n",
        "    user_input=\"\"\n",
        "    st.title(\"Tildha AI - Health Assistant\")\n",
        "    st.sidebar.title(\"Tildha AI Menu\")\n",
        "    menu = st.sidebar.radio(\"Select Mode\", (\"Text to Text\", \"Text to Speech\", \"Speech to Text\", \"Speech to Speech\"))\n",
        "    if menu == \"Text to Text\":\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(\"Hello users, I am Tildha your health assistant!\")\n",
        "      text_to_text()\n",
        "\n",
        "    elif menu == \"Text to Speech\":\n",
        "      teks = \"Hello user, how can I help you?\"\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(teks)\n",
        "      audioFile = generate_speech(teks)\n",
        "      st.audio(audioFile, format='audio/wav', autoplay=False)\n",
        "      text_to_speech()\n",
        "\n",
        "    elif menu == \"Speech to Text\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      teks = \"Hello user, how can I help you?\"\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(teks)\n",
        "      st.divider()\n",
        "      st.write(\"History conversation: \")\n",
        "      speech_to_text()\n",
        "\n",
        "    elif menu == \"Speech to Speech\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      audio_data = get_audio()\n",
        "      if audio_data:\n",
        "        binary = b64decode(audio_data.split(\",\")[1])\n",
        "        wav_file = io.BytesIO(binary)\n",
        "        wav_data = wav_read(wav_file)\n",
        "        recognizer = sr.Recognizer()\n",
        "        with sr.AudioFile(io.BytesIO(wav_data)) as source:\n",
        "          audio = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        response = generate_response(text)\n",
        "        response_translated = translate_text(response)\n",
        "        display_speech(response_translated)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "PcBODcK_zwfy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d32a1fb-c40b-4091-97a0-5111d298a1ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dec1MUNze_20",
        "outputId": "b072ee74-b057-40d3-a136-8ddedbafde8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.143.128.240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Bwcai8RfAWk",
        "outputId": "2051e5f2-8384-4b51-d0aa-e761c445c258"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your url is: https://red-streets-obey.loca.lt\n"
          ]
        }
      ]
    }
  ]
}