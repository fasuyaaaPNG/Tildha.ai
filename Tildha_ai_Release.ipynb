{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNl4gF7r8De/j2UFLJdHNAD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fasuyaaaPNG/Tildha.ai/blob/main/Tildha_ai_Release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependensi"
      ],
      "metadata": {
        "id": "RkpSFxn2zVZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8oxSrx1zFlU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install ffmpeg-python\n",
        "!pip install assemblyai\n",
        "!pip install PyAudio\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts\n",
        "!pip install -q streamlit\n",
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart kernel"
      ],
      "metadata": {
        "id": "kzxUWDAazUON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quit()"
      ],
      "metadata": {
        "id": "knYr9ULHzcNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access granted\n",
        "\n",
        "(rerun cell after allow first allert)"
      ],
      "metadata": {
        "id": "5559nOsizea6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"\");\n",
        "my_btn.appendChild(t);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Inisialisasi base64data\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Untuk melacak status rekaman\n",
        "\n",
        "// Fungsi yang dipanggil saat perekaman berhasil\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    mimeType: 'audio/webm;codecs=opus'\n",
        "  };\n",
        "  recorder = new MediaRecorder(stream);\n",
        "\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Audio data in base64: \", base64data);\n",
        "    };\n",
        "  };\n",
        "\n",
        "  recorder.onstop = function() {\n",
        "    console.log(\"Recording stopped, data is ready\");\n",
        "    resolve(base64data);\n",
        "  };\n",
        "};\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true})\n",
        "  .then(handleSuccess)\n",
        "  .catch(function(e) {\n",
        "    console.error('getUserMedia error:', e);\n",
        "  });\n",
        "\n",
        "// recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      // recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      // recordButton.innerText = \"Recording finished\";\n",
        "      // Resolusi dijalankan di recorder.onstop\n",
        "    }\n",
        "  };\n",
        "});\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(AUDIO_HTML))"
      ],
      "metadata": {
        "id": "-7Brctvzzggy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Version"
      ],
      "metadata": {
        "id": "i9ZGQUTLzkFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "import torch\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# List of libraries you want to check versions for\n",
        "libraries = [\n",
        "    'unsloth', 'xformers', 'trl', 'peft', 'accelerate', 'bitsandbytes',\n",
        "    'torchaudio', 'omegaconf', 'ffmpeg-python', 'assemblyai', 'PyAudio',\n",
        "    'googletrans', 'SpeechRecognition', 'gtts'\n",
        "]\n",
        "\n",
        "# Print library versions\n",
        "print(\"Library versions:\")\n",
        "for lib in libraries:\n",
        "    try:\n",
        "        version = pkg_resources.get_distribution(lib).version\n",
        "        print(f'{lib}: {version}')\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        print(f'{lib} is not installed')\n",
        "\n",
        "# Print CUDA version\n",
        "if torch.cuda.is_available():\n",
        "    print(f'\\nCUDA Version: {torch.version.cuda}')\n",
        "else:\n",
        "    print('\\nCUDA Version: Not available')\n",
        "\n",
        "# GPU information\n",
        "if torch.cuda.is_available():\n",
        "    print(f'\\nGPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('\\nGPU: Not available')\n",
        "\n",
        "# Print OS and GPU information\n",
        "print(f'\\nOperating System: {platform.system()} {platform.release()}')\n",
        "print(f'Platform: {platform.platform()}')"
      ],
      "metadata": {
        "id": "sStmRkEwzk8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tildha Release v1.0"
      ],
      "metadata": {
        "id": "lkhUlNRlzsIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "import streamlit as st\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "if 'conversation' not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "\n",
        "# def update_context(key, value):\n",
        "#     global_context[key] = value\n",
        "\n",
        "# def get_context(key):\n",
        "#     return global_context.get(key, None)\n",
        "\n",
        "# def process_input(user_input):\n",
        "#     last_input = get_context(\"last_user_input\")\n",
        "#     if last_input:\n",
        "#         user_input = f\"Previously, you said: {last_input}. Now, you say: {user_input}\"\n",
        "\n",
        "#     update_context(\"last_user_input\", user_input)\n",
        "#     return user_input\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  st.components.v1.html(AUDIO_HTML)\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return st.session_state.get(\"audio\", None)\n",
        "\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return AutoModelForCausalLM.from_pretrained(\n",
        "        \"Lvyn/AI-Tildha-Merged\",\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        "    )\n",
        "\n",
        "# Load the model\n",
        "model = load_model()\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  print(\"\")\n",
        "  display(Audio(audio, rate=48000, autoplay=True))\n",
        "  print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  if \"messages\" not in st.session_state:\n",
        "    st.session_state.messages = []\n",
        "  for message in st.session_state.messages:\n",
        "    with st.chat_message(message[\"role\"]):\n",
        "        st.markdown(message[\"content\"])\n",
        "  if prompt := st.chat_input(\"Ask Tildha\"):\n",
        "    st.chat_message(\"user\").markdown(prompt)\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    with st.chat_message(\"assistant\"):\n",
        "      response = generate_response(prompt)\n",
        "      lang = detect_lang(prompt)\n",
        "      response = translate(lang, response)\n",
        "      responseTildha = f\"Tildha: {response}\"\n",
        "      st.markdown(responseTildha)\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": responseTildha})\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      time.sleep(1)\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "      time.sleep(1)\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       id_lang = detect_lang(user_input)\n",
        "       responses = translate(id_lang, response)\n",
        "       if id_lang == \"indonesian\" :\n",
        "          generate_indonesian_speech(responses)\n",
        "       else :\n",
        "          generate_speech(responses)\n",
        "       print(f\"Tildha: {responses}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    time.sleep(1)\n",
        "    user_input=\"\"\n",
        "    st.title(\"Tildha AI - Health Assistant\")\n",
        "    st.sidebar.title(\"Tildha AI Menu\")\n",
        "    menu = st.sidebar.radio(\"Select Mode\", (\"Text to Text\", \"Text to Speech\", \"Speech to Text\", \"Speech to Speech\"))\n",
        "    if menu == \"Text to Text\":\n",
        "        text_to_text()\n",
        "\n",
        "    elif menu == \"Text to Speech\":\n",
        "      user_input = st.text_input(\"You: \")\n",
        "      if user_input:\n",
        "        response = generate_response(user_input)\n",
        "        response_translated = translate_text(response)\n",
        "        display_speech(response_translated)\n",
        "\n",
        "    elif menu == \"Speech to Text\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      audio_data = get_audio()\n",
        "      if audio_data:\n",
        "        binary = b64decode(audio_data.split(\",\")[1])\n",
        "        wav_file = io.BytesIO(binary)\n",
        "        wav_data = wav_read(wav_file)\n",
        "        recognizer = sr.Recognizer()\n",
        "        with sr.AudioFile(io.BytesIO(wav_data)) as source:\n",
        "          audio = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        st.write(f\"You said: {text}\")\n",
        "        response = generate_response(text)\n",
        "        st.write(f\"Tildha: {response}\")\n",
        "\n",
        "    elif menu == \"Speech to Speech\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      audio_data = get_audio()\n",
        "      if audio_data:\n",
        "        binary = b64decode(audio_data.split(\",\")[1])\n",
        "        wav_file = io.BytesIO(binary)\n",
        "        wav_data = wav_read(wav_file)\n",
        "        recognizer = sr.Recognizer()\n",
        "        with sr.AudioFile(io.BytesIO(wav_data)) as source:\n",
        "          audio = recognizer.record(source)\n",
        "        text = recognizer.recognize_google(audio)\n",
        "        response = generate_response(text)\n",
        "        response_translated = translate_text(response)\n",
        "        display_speech(response_translated)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "PcBODcK_zwfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "id": "dec1MUNze_20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "2Bwcai8RfAWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}