{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1_gX30wZH6O79Qcpg0VKuhNTaFeQrbOYg",
      "authorship_tag": "ABX9TyN2bEg9PxB5S4mgDl7voqNG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fasuyaaaPNG/Tildha.ai/blob/main/Tildha_ai_Release.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dependensi"
      ],
      "metadata": {
        "id": "RkpSFxn2zVZZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q8oxSrx1zFlU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install ffmpeg-python\n",
        "!pip install assemblyai\n",
        "!pip install PyAudio\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts\n",
        "!pip install -q streamlit\n",
        "!npm install localtunnel@2.0.2\n",
        "!pip install langdetect\n",
        "!pip install streamlit-audiorecorder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart kernel"
      ],
      "metadata": {
        "id": "kzxUWDAazUON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quit()"
      ],
      "metadata": {
        "id": "knYr9ULHzcNa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download 2 photos for user profile and AI\n",
        "\n",
        "user.svg: https://drive.google.com/file/d/1zUlHX0q3OLSNQWdMH403vvjYLirD4Tip/view?usp=drive_link\n",
        "\n",
        "logo.svg https://drive.google.com/file/d/1NWJeFny726e5ol7XlEAexnFiCoUhdd5D/view?usp=drive_link\n",
        "\n",
        "\n",
        "**Important note: Before running the code \"Tildha Release v1.0\", make sure you have uploaded the 2 svg files above to the files folder on the left.**\n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAC4AAAA6CAYAAADP/mu6AAAACXBIWXMAAA7EAAAOxAGVKw4bAAABfUlEQVRoge3avUrDUBjG8SeJrbUKbUColEYwTiIqDkq8CgWdXRyKgoP34VAQwV3cvQihDoogOKUqaAt+I/WTNE0cxKm26ckJbwm8/7E5yflx6ElKiWJZlo8YpvYaEDaGU8dw6hhOHcOpU+620j4ALJWne20RKrYrznDqGE4dw6ljOHV9IoNnMu/YHL/FcH/j3+Pb9iiOnrKRwIISWvF1s9oWDQDFsRr0pCuN6iahFR9JOQCA1ZPJlmPL+Qcs5h+xYVZRso2O1/nyNHiS/y0Iwf+qN7SWz/ZvcpjV3zCn13Ewf9Hx/M+mip2KgfJLJsz0ACLcnK6vomQbcH0lcGxa81A0a1LzhVrxdl19DGDleCpw3OHCObIJub0Q29shw6ljOHUMpy628FAPoEGtGbVDOCH4/XcSuZQT+Fukm56dhNT5Ql+VveuC9ITAL3r3siB1DaEVP3sdwtrphNSEURXbzclw6hhOHcOpYzh1sYUr/L4KcQynjuHUMZw6hlP3A4gVTB6jD9w8AAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "V0IhzOhp-GST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tildha Release v1.0"
      ],
      "metadata": {
        "id": "lkhUlNRlzsIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "import os\n",
        "import streamlit as st\n",
        "from audiorecorder import audiorecorder\n",
        "from scipy.io.wavfile import write as wav_write\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "if 'conversation' not in st.session_state:\n",
        "    st.session_state.conversation = []\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "@st.cache_resource\n",
        "def load_model():\n",
        "    return AutoModelForCausalLM.from_pretrained(\n",
        "        \"Lvyn/AI-Tildha-Merged\",\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        "    )\n",
        "\n",
        "model = load_model()\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(text):\n",
        "    bahasa = \"en\"\n",
        "    file = gTTS(text = text, lang=bahasa)\n",
        "    file.save(\"speech.wav\")\n",
        "\n",
        "    with open(\"speech.wav\", 'rb') as f :\n",
        "      audio = f.read()\n",
        "\n",
        "    return audio\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  return audio\n",
        "\n",
        "def text_to_text():\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "    if prompt := st.chat_input(\"Ask Tildha\"):\n",
        "        st.chat_message('User', avatar=\"/content/user.svg\").markdown(prompt)\n",
        "        st.session_state.messages.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": prompt})\n",
        "        with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "            response = generate_response(prompt)\n",
        "            lang = detect_lang(prompt)\n",
        "            response = translate(lang, response)\n",
        "            responseTildha = f\"Tildha: {response}\"\n",
        "            st.markdown(responseTildha)\n",
        "        st.session_state.messages.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responseTildha})\n",
        "\n",
        "\n",
        "def text_to_speech():\n",
        "    if \"messagesTS\" not in st.session_state:\n",
        "        st.session_state.messagesTS = []\n",
        "\n",
        "    for message in st.session_state.messagesTS:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            if message[\"role\"] == \"User\":\n",
        "                st.markdown(message[\"content\"])\n",
        "            elif message[\"role\"] == \"Tildha\":\n",
        "                if message[\"content\"] != \"Audio response\":\n",
        "                    st.markdown(message[\"content\"])\n",
        "                    audio_file = generate_speech(message[\"content\"])\n",
        "                    st.audio(audio_file, format='audio/wav', autoplay=False)\n",
        "\n",
        "    if prompt := st.chat_input(\"Ask Tildha\"):\n",
        "        st.chat_message('User', avatar=\"/content/user.svg\").markdown(prompt)\n",
        "        st.session_state.messagesTS.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": prompt})\n",
        "\n",
        "        with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "            response = generate_response(prompt)\n",
        "            id_lang = detect_lang(prompt)\n",
        "            responses = translate(id_lang, response)\n",
        "\n",
        "            if id_lang == \"indonesian\":\n",
        "                audioFile = generate_indonesian_speech(responses)\n",
        "            else:\n",
        "                audioFile = generate_speech(responses)\n",
        "\n",
        "            st.session_state.messagesTS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responses})\n",
        "            st.markdown(responses)\n",
        "            st.audio(audioFile, format='audio/wav', autoplay=True)\n",
        "\n",
        "        # st.session_state.messagesTS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": \"Audio response\"})\n",
        "\n",
        "\n",
        "def speech_to_text():\n",
        "    audio_file_path = \"./output.wav\"\n",
        "    try:\n",
        "        if os.path.exists(audio_file_path):\n",
        "            os.remove(audio_file_path)\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "    if \"messagesST\" not in st.session_state:\n",
        "        st.session_state.messagesST = []\n",
        "    for message in st.session_state.messagesST:\n",
        "        with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "    st.divider()\n",
        "\n",
        "    option = st.selectbox(\n",
        "        \"select AI voice accent\",\n",
        "        [\"Indonesian\", \"English\"]\n",
        "    )\n",
        "\n",
        "    audio = audiorecorder(\"ðŸ—£ï¸ Click to record\", \"ðŸ«¢ Click to stop recording\")\n",
        "\n",
        "    if len(audio) > 0:\n",
        "        try:\n",
        "            audio.export(audio_file_path, format=\"wav\")\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error saving audio file: {e}\")\n",
        "            return\n",
        "\n",
        "    speech = \"\"\n",
        "\n",
        "    if os.path.exists(audio_file_path):\n",
        "        if option == \"Indonesian\":\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "        elif option == \"English\":\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "    else:\n",
        "        st.error(\"Please select language selection.\")\n",
        "        return\n",
        "\n",
        "    if not speech:\n",
        "        st.error(\"No speech generated.\")\n",
        "        return\n",
        "\n",
        "    st.chat_message('User', avatar=\"/content/user.svg\").markdown(speech)\n",
        "    st.session_state.messagesST.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": speech})\n",
        "\n",
        "    with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "        response = generate_response(speech)\n",
        "        id_lang = detect_lang(speech)\n",
        "        responses = translate(id_lang, response)\n",
        "        responseTildha = f\"Tildha: {responses}\"\n",
        "        st.markdown(responseTildha)\n",
        "\n",
        "    st.session_state.messagesST.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responseTildha})\n",
        "\n",
        "def speech_to_speech():\n",
        "  audio_file_path = \"./output.wav\"\n",
        "  try:\n",
        "    if os.path.exists(audio_file_path):\n",
        "      os.remove(audio_file_path)\n",
        "  except FileNotFoundError:\n",
        "    pass\n",
        "  if \"messagesSS\" not in st.session_state:\n",
        "    st.session_state.messagesSS = []\n",
        "  for message in st.session_state.messagesSS:\n",
        "    with st.chat_message(message[\"role\"], avatar=message[\"pp\"]):\n",
        "      if message[\"role\"] == \"User\":\n",
        "        st.markdown(message[\"content\"])\n",
        "      elif message[\"role\"] == \"Tildha\":\n",
        "        if message[\"content\"] != \"Audio response\":\n",
        "          st.markdown(message[\"content\"])\n",
        "          audio_file = generate_speech(message[\"content\"])\n",
        "          st.audio(audio_file, format='audio/wav', autoplay=False)\n",
        "  st.divider()\n",
        "  option = st.selectbox(\n",
        "    \"select AI voice accent\",\n",
        "    [\"Indonesian\", \"English\"]\n",
        "  )\n",
        "  audio = audiorecorder(\"ðŸ—£ï¸ Click to record\", \"ðŸ«¢ Click to stop recording\")\n",
        "\n",
        "  if len(audio) > 0:\n",
        "    try:\n",
        "      audio.export(audio_file_path, format=\"wav\")\n",
        "    except Exception as e:\n",
        "      st.error(f\"Error saving audio file: {e}\")\n",
        "      return\n",
        "\n",
        "  speech = \"\"\n",
        "\n",
        "  if os.path.exists(audio_file_path):\n",
        "    if option == \"Indonesian\":\n",
        "      speech = generate_text_from_speech(\"id-ID\")\n",
        "    elif option == \"English\":\n",
        "      speech = generate_text_from_speech(\"en-EN\")\n",
        "  else:\n",
        "    st.error(\"Please select language selection.\")\n",
        "    return\n",
        "\n",
        "  if not speech:\n",
        "    st.error(\"No speech generated.\")\n",
        "    return\n",
        "\n",
        "  st.chat_message('User', avatar=\"/content/user.svg\").markdown(speech)\n",
        "  st.session_state.messagesSS.append({\"role\": \"User\", \"pp\": \"/content/user.svg\", \"content\": speech})\n",
        "\n",
        "  with st.chat_message('Tildha', avatar=\"/content/logo.svg\"):\n",
        "    response = generate_response(speech)\n",
        "    id_lang = detect_lang(speech)\n",
        "    responses = translate(id_lang, response)\n",
        "    if id_lang == \"indonesian\" :\n",
        "      audioFile = generate_indonesian_speech(responses)\n",
        "    else :\n",
        "      audioFile = generate_speech(responses)\n",
        "    st.session_state.messagesSS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responses})\n",
        "    st.markdown(responses)\n",
        "    st.audio(audioFile, format='audio/wav', autoplay=True)\n",
        "\n",
        "  # st.session_state.messagesSS.append({\"role\": \"Tildha\", \"pp\": \"/content/logo.svg\", \"content\": responseTildha})\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    time.sleep(1)\n",
        "    user_input=\"\"\n",
        "    st.title(\"Tildha AI - Health Assistant\")\n",
        "    st.sidebar.title(\"Tildha AI Menu\")\n",
        "    menu = st.sidebar.radio(\"Select Mode\", (\"Text to Text\", \"Text to Speech\", \"Speech to Text\", \"Speech to Speech\"))\n",
        "    if menu == \"Text to Text\":\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(\"Hello users, I am Tildha your health assistant!\")\n",
        "      text_to_text()\n",
        "\n",
        "    elif menu == \"Text to Speech\":\n",
        "      teks = \"Hello user, how can I help you?\"\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(teks)\n",
        "      audioFile = generate_speech(teks)\n",
        "      st.audio(audioFile, format='audio/wav', autoplay=False)\n",
        "      text_to_speech()\n",
        "\n",
        "    elif menu == \"Speech to Text\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      teks = \"Hello user, just say what you need!\"\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(teks)\n",
        "      st.divider()\n",
        "      st.write(\"History conversation: \")\n",
        "      speech_to_text()\n",
        "\n",
        "    elif menu == \"Speech to Speech\":\n",
        "      st.write(\"Click the button to start recording your speech.\")\n",
        "      teks = \"Hello user, say something!\"\n",
        "      Ai = st.chat_message('Tildha', avatar=\"/content/logo.svg\")\n",
        "      Ai.write(teks)\n",
        "      st.divider()\n",
        "      st.write(\"History conversation: \")\n",
        "      speech_to_speech()\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "id": "PcBODcK_zwfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "id": "dec1MUNze_20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py &>/content/logs.txt & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "2Bwcai8RfAWk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}