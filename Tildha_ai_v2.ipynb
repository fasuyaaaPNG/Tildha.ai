{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNUfYfbaqbwSIRvcRYGqn/l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8c40fb079b474f4ab6fb3ec97f895225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f40f50c77c0443ba8b736fb883e819b",
              "IPY_MODEL_7571c2a00d074a53a2a262ee03ef3297",
              "IPY_MODEL_7cb31b92fd5648cf9cccdf557a5db23c"
            ],
            "layout": "IPY_MODEL_c17885ef4c2b431d855bd21e618c5f33"
          }
        },
        "7f40f50c77c0443ba8b736fb883e819b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ce17af533934a2791ffba775f1f4634",
            "placeholder": "​",
            "style": "IPY_MODEL_9f40c5be55db484082896f1795fb234a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7571c2a00d074a53a2a262ee03ef3297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c8dc8ba7064c6ca170a3fee9c38a98",
            "max": 50614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29470ecc9e51410bbbe113d7d243ddc0",
            "value": 50614
          }
        },
        "7cb31b92fd5648cf9cccdf557a5db23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0398ff75fd71482a8bb58f8bf26f06ed",
            "placeholder": "​",
            "style": "IPY_MODEL_b072cf01c6624d449b53325e59fcc5a9",
            "value": " 50.6k/50.6k [00:00&lt;00:00, 3.31MB/s]"
          }
        },
        "c17885ef4c2b431d855bd21e618c5f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ce17af533934a2791ffba775f1f4634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f40c5be55db484082896f1795fb234a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81c8dc8ba7064c6ca170a3fee9c38a98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29470ecc9e51410bbbe113d7d243ddc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0398ff75fd71482a8bb58f8bf26f06ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b072cf01c6624d449b53325e59fcc5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56d337ddedad45e68ef247aa4f033a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2ad24b40496342e290aa590981d8e5ef",
              "IPY_MODEL_dc4875e56a014c169942c16a34324c43",
              "IPY_MODEL_eb13b1042c504bb98274065b109ac18a"
            ],
            "layout": "IPY_MODEL_8d0e421834fc487496e681335b135311"
          }
        },
        "2ad24b40496342e290aa590981d8e5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_facd4fea95b24db6bad460d4a6a4d2b2",
            "placeholder": "​",
            "style": "IPY_MODEL_365b6def49624d01b043790194c201ee",
            "value": "tokenizer.json: 100%"
          }
        },
        "dc4875e56a014c169942c16a34324c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a549c2366e224a8d9ee163ed310628a2",
            "max": 9085698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b28c6a27ffd40dc934f77a000959cbc",
            "value": 9085698
          }
        },
        "eb13b1042c504bb98274065b109ac18a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5022462078674a3686da1726f085bf23",
            "placeholder": "​",
            "style": "IPY_MODEL_d889d4b5cfa641c3a41ffb624ef382dd",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 21.9MB/s]"
          }
        },
        "8d0e421834fc487496e681335b135311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "facd4fea95b24db6bad460d4a6a4d2b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365b6def49624d01b043790194c201ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a549c2366e224a8d9ee163ed310628a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b28c6a27ffd40dc934f77a000959cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5022462078674a3686da1726f085bf23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d889d4b5cfa641c3a41ffb624ef382dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9abbf60e2dd24de3be92b0adc779dc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cccb38a8e1f42499294e5cd081787e4",
              "IPY_MODEL_8b5aa7d72e9849fab07e990b53a5d833",
              "IPY_MODEL_58e894752b2240dcbc78abef524c2c8a"
            ],
            "layout": "IPY_MODEL_c32d89af36fe4c1989e7047db0a95150"
          }
        },
        "9cccb38a8e1f42499294e5cd081787e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee0762273634f7a88ebf9f3b709a306",
            "placeholder": "​",
            "style": "IPY_MODEL_f6fdd09e57be4fe5853e52580f74c4be",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "8b5aa7d72e9849fab07e990b53a5d833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6a6e18383247fd84a90b0eb2df4307",
            "max": 464,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6a5ab215aa0a40b59ca9613e513deb90",
            "value": 464
          }
        },
        "58e894752b2240dcbc78abef524c2c8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e41c5af84a4f74a3ec4f5e4296f84a",
            "placeholder": "​",
            "style": "IPY_MODEL_cd02cb8e2bde4fd68e545ee90b917325",
            "value": " 464/464 [00:00&lt;00:00, 27.2kB/s]"
          }
        },
        "c32d89af36fe4c1989e7047db0a95150": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ee0762273634f7a88ebf9f3b709a306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6fdd09e57be4fe5853e52580f74c4be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e6a6e18383247fd84a90b0eb2df4307": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a5ab215aa0a40b59ca9613e513deb90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7e41c5af84a4f74a3ec4f5e4296f84a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd02cb8e2bde4fd68e545ee90b917325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60fed79d7d784d4a876ef7c259c2fb9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_412c3dafd3a24a85b554aaa7630d1693",
              "IPY_MODEL_3571bf3a91674346815b44b36690cff8",
              "IPY_MODEL_816519a9f7e345d688e0ed0e5e44e881"
            ],
            "layout": "IPY_MODEL_619ab716b7da4d08bcb2c3ef3d4f5b21"
          }
        },
        "412c3dafd3a24a85b554aaa7630d1693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef674bb6780b4cd9b45fbe8efa1f56ab",
            "placeholder": "​",
            "style": "IPY_MODEL_b164d5fea177469ebd5b3c917141388a",
            "value": "config.json: 100%"
          }
        },
        "3571bf3a91674346815b44b36690cff8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44897e2f0b824dfbbf6818ae1c9dd62b",
            "max": 776,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e5660b138141ffb5d05fe8271aa041",
            "value": 776
          }
        },
        "816519a9f7e345d688e0ed0e5e44e881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9953eea384e4e2682d31878c881da44",
            "placeholder": "​",
            "style": "IPY_MODEL_2e606008b82e475a9d16b6845b94780a",
            "value": " 776/776 [00:00&lt;00:00, 45.9kB/s]"
          }
        },
        "619ab716b7da4d08bcb2c3ef3d4f5b21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef674bb6780b4cd9b45fbe8efa1f56ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b164d5fea177469ebd5b3c917141388a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44897e2f0b824dfbbf6818ae1c9dd62b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e5660b138141ffb5d05fe8271aa041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9953eea384e4e2682d31878c881da44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e606008b82e475a9d16b6845b94780a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e768c84a5214f2fb1fd02fe55402c76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_302556d073d447feb2c8972fff7a43f1",
              "IPY_MODEL_691b0dde075e494fa1760df1644ee6a6",
              "IPY_MODEL_6c2b659e03064deb8453a3ba4cc35138"
            ],
            "layout": "IPY_MODEL_9ad50b4ddff4435093f72870cfc35e29"
          }
        },
        "302556d073d447feb2c8972fff7a43f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7922ac6f15744a5892e81cc619d5f8d2",
            "placeholder": "​",
            "style": "IPY_MODEL_1f7d8eb3e0cf4cf7a5caa055411bef95",
            "value": "adapter_config.json: 100%"
          }
        },
        "691b0dde075e494fa1760df1644ee6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b0b3ab630645eda16fc1275e2c28a0",
            "max": 732,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eea94f7ea93c43d781e71f900eb7e6bf",
            "value": 732
          }
        },
        "6c2b659e03064deb8453a3ba4cc35138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b583adf31fc1444db69a5c8a77d4fa9b",
            "placeholder": "​",
            "style": "IPY_MODEL_5d22596243a54e648e08a648726f51a1",
            "value": " 732/732 [00:00&lt;00:00, 45.8kB/s]"
          }
        },
        "9ad50b4ddff4435093f72870cfc35e29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7922ac6f15744a5892e81cc619d5f8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f7d8eb3e0cf4cf7a5caa055411bef95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6b0b3ab630645eda16fc1275e2c28a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eea94f7ea93c43d781e71f900eb7e6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b583adf31fc1444db69a5c8a77d4fa9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d22596243a54e648e08a648726f51a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ef37653cb3402798b1b2d3174b9421": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b78437ac4bec418c9b2a40233bfffd80",
              "IPY_MODEL_d5d8fb2be29a47a2a7eebb2fc1b4a6c4",
              "IPY_MODEL_af2f00c61abd439e8cb3c7813e19c7b7"
            ],
            "layout": "IPY_MODEL_b68acbfaece149eeab06485443f90d40"
          }
        },
        "b78437ac4bec418c9b2a40233bfffd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20cd8b4b0d2b4554b228cef1f3e8ffe5",
            "placeholder": "​",
            "style": "IPY_MODEL_7c750f6319554f07a8c655771b85191c",
            "value": "config.json: 100%"
          }
        },
        "d5d8fb2be29a47a2a7eebb2fc1b4a6c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b03618f89e475e990c2835a802e678",
            "max": 1249,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_194478937e384ecd85c3ec4b927465f1",
            "value": 1249
          }
        },
        "af2f00c61abd439e8cb3c7813e19c7b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e873d94f5534ba69eb693fae545adde",
            "placeholder": "​",
            "style": "IPY_MODEL_002fe0b5cdab4fd4b3b77affd52c33e9",
            "value": " 1.25k/1.25k [00:00&lt;00:00, 53.8kB/s]"
          }
        },
        "b68acbfaece149eeab06485443f90d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20cd8b4b0d2b4554b228cef1f3e8ffe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c750f6319554f07a8c655771b85191c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b03618f89e475e990c2835a802e678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194478937e384ecd85c3ec4b927465f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e873d94f5534ba69eb693fae545adde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002fe0b5cdab4fd4b3b77affd52c33e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a23b5c216614aefaa79c73876ab0503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c71db8226a32416a8b14e92f36393e47",
              "IPY_MODEL_769ca1d645f64f4abfd5527e721e2c64",
              "IPY_MODEL_0be7b07c6b2f4752a0981e703394f5dd"
            ],
            "layout": "IPY_MODEL_cad5b1f4e27e448ab8811268ebe8aa6c"
          }
        },
        "c71db8226a32416a8b14e92f36393e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a0a5c40c4cf4a799e54a6b3b0b3fec0",
            "placeholder": "​",
            "style": "IPY_MODEL_09fc1bd94f0e43a789d1f87e0bb49aba",
            "value": "model.safetensors:   3%"
          }
        },
        "769ca1d645f64f4abfd5527e721e2c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_423e3efe774f4bdb9e739873284c085e",
            "max": 5702746405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53316abb0eb94886b768adb30a35dc19",
            "value": 199229440
          }
        },
        "0be7b07c6b2f4752a0981e703394f5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d188121d68864b4f8fd711d7774e8487",
            "placeholder": "​",
            "style": "IPY_MODEL_1ca2f2dc742c4c2aa4243334d58dc738",
            "value": " 199M/5.70G [00:01&lt;00:38, 144MB/s]"
          }
        },
        "cad5b1f4e27e448ab8811268ebe8aa6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a0a5c40c4cf4a799e54a6b3b0b3fec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09fc1bd94f0e43a789d1f87e0bb49aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "423e3efe774f4bdb9e739873284c085e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53316abb0eb94886b768adb30a35dc19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d188121d68864b4f8fd711d7774e8487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ca2f2dc742c4c2aa4243334d58dc738": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c8efe2d7e234d7c81183505a22e3ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4cf4409c1d649178dc8785c49c8daae",
              "IPY_MODEL_78e6ec68b2b640f59423e5ca363df4d0",
              "IPY_MODEL_05d6acf887e241439550a86db81d5249"
            ],
            "layout": "IPY_MODEL_d030dc02986546308e1f99f6d195178b"
          }
        },
        "a4cf4409c1d649178dc8785c49c8daae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b35d00d22e14d6a80cd58ce8d26d613",
            "placeholder": "​",
            "style": "IPY_MODEL_8156029018544159b350f115a7da7ccd",
            "value": "model.safetensors: 100%"
          }
        },
        "78e6ec68b2b640f59423e5ca363df4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_749400df9a3f46de92cbf5a9d6ed7a5f",
            "max": 5702746405,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_53902e5b0b1748ed881507266c4179f7",
            "value": 5702746405
          }
        },
        "05d6acf887e241439550a86db81d5249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4237a7ae3ee2419c93a716144417113d",
            "placeholder": "​",
            "style": "IPY_MODEL_0f3c348263c7442295857ed17cda82d5",
            "value": " 5.70G/5.70G [00:41&lt;00:00, 134MB/s]"
          }
        },
        "d030dc02986546308e1f99f6d195178b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b35d00d22e14d6a80cd58ce8d26d613": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8156029018544159b350f115a7da7ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "749400df9a3f46de92cbf5a9d6ed7a5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53902e5b0b1748ed881507266c4179f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4237a7ae3ee2419c93a716144417113d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f3c348263c7442295857ed17cda82d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "711aa5e856eb41f09be8e95788edf8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5467a9b8c774c95b2251ecf5919a05c",
              "IPY_MODEL_8252eb77c9764991902e5a3fb60e1010",
              "IPY_MODEL_9e8543ac73f243a8b7fed93b9182e092"
            ],
            "layout": "IPY_MODEL_53d618fcc7dd432dbff4052f3fd0250c"
          }
        },
        "d5467a9b8c774c95b2251ecf5919a05c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e98e63e603045978bd04df142eedd4e",
            "placeholder": "​",
            "style": "IPY_MODEL_f4163b78e53e475fbda2d9bad59a2b91",
            "value": "generation_config.json: 100%"
          }
        },
        "8252eb77c9764991902e5a3fb60e1010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf55e4971394a7697514dd42f36de8a",
            "max": 198,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7b874afe03146f294f54355c2201355",
            "value": 198
          }
        },
        "9e8543ac73f243a8b7fed93b9182e092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a0d595534a4899917e64b04f6f19ec",
            "placeholder": "​",
            "style": "IPY_MODEL_24dfd324334a49589403fb8f6aaf6f53",
            "value": " 198/198 [00:00&lt;00:00, 15.5kB/s]"
          }
        },
        "53d618fcc7dd432dbff4052f3fd0250c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e98e63e603045978bd04df142eedd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4163b78e53e475fbda2d9bad59a2b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bf55e4971394a7697514dd42f36de8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b874afe03146f294f54355c2201355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0a0d595534a4899917e64b04f6f19ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24dfd324334a49589403fb8f6aaf6f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384fc31be552481c94814fab1f9da8f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7e39e30316dd46599479a64a7d194893",
              "IPY_MODEL_d871211a8838424498669729db35abb1",
              "IPY_MODEL_16434a12a88f487a8aed1e3dd1214150"
            ],
            "layout": "IPY_MODEL_fba430b9ac1349edbbc6894d1406bf35"
          }
        },
        "7e39e30316dd46599479a64a7d194893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e4024cffed142dc805883e71a5b419b",
            "placeholder": "​",
            "style": "IPY_MODEL_fd5dfb7750be4ebba5305bfaa6b9cadd",
            "value": "adapter_model.safetensors: 100%"
          }
        },
        "d871211a8838424498669729db35abb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60ecf5035134f32851fb472723d9d9a",
            "max": 167832240,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_51f1231786a44f26a6cf01b015cdcf8a",
            "value": 167832240
          }
        },
        "16434a12a88f487a8aed1e3dd1214150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_911df9b3e7a04ee1abc82a7ad015c399",
            "placeholder": "​",
            "style": "IPY_MODEL_a03daf5a91f3470d8a6552f1dd9ab1af",
            "value": " 168M/168M [00:00&lt;00:00, 254MB/s]"
          }
        },
        "fba430b9ac1349edbbc6894d1406bf35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4024cffed142dc805883e71a5b419b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd5dfb7750be4ebba5305bfaa6b9cadd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60ecf5035134f32851fb472723d9d9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51f1231786a44f26a6cf01b015cdcf8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "911df9b3e7a04ee1abc82a7ad015c399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03daf5a91f3470d8a6552f1dd9ab1af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fasuyaaaPNG/Tildha.ai/blob/main/Tildha_ai_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dependensi"
      ],
      "metadata": {
        "id": "N8FkiSviG6X6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuvd3nOUG1Ks"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install ffmpeg-python\n",
        "!pip install assemblyai\n",
        "!pip install PyAudio\n",
        "!pip install googletrans==3.1.0a0\n",
        "!pip install SpeechRecognition\n",
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart kernel"
      ],
      "metadata": {
        "id": "yyveziEaHE21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quit()"
      ],
      "metadata": {
        "id": "eUNGYn9iHHd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Access granted\n",
        "\n",
        "(rerun cell after allow first allert)"
      ],
      "metadata": {
        "id": "qQLwqTDn4n58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"\");\n",
        "my_btn.appendChild(t);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Inisialisasi base64data\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Untuk melacak status rekaman\n",
        "\n",
        "// Fungsi yang dipanggil saat perekaman berhasil\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    mimeType: 'audio/webm;codecs=opus'\n",
        "  };\n",
        "  recorder = new MediaRecorder(stream);\n",
        "\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Audio data in base64: \", base64data);\n",
        "    };\n",
        "  };\n",
        "\n",
        "  recorder.onstop = function() {\n",
        "    console.log(\"Recording stopped, data is ready\");\n",
        "    resolve(base64data);\n",
        "  };\n",
        "};\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true})\n",
        "  .then(handleSuccess)\n",
        "  .catch(function(e) {\n",
        "    console.error('getUserMedia error:', e);\n",
        "  });\n",
        "\n",
        "// recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      // recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      // recordButton.innerText = \"Recording finished\";\n",
        "      // Resolusi dijalankan di recorder.onstop\n",
        "    }\n",
        "  };\n",
        "});\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(AUDIO_HTML))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "WfU7nfJ84d8q",
        "outputId": "10c2d186-2338-463b-f0fd-f050d341a79a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"\");\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = \"\";  // Inisialisasi base64data\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "var isRecording = false;  // Untuk melacak status rekaman\n",
              "\n",
              "// Fungsi yang dipanggil saat perekaman berhasil\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType: 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      console.log(\"Audio data in base64: \", base64data);\n",
              "    };\n",
              "  };\n",
              "\n",
              "  recorder.onstop = function() {\n",
              "    console.log(\"Recording stopped, data is ready\");\n",
              "    resolve(base64data);\n",
              "  };\n",
              "};\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true})\n",
              "  .then(handleSuccess)\n",
              "  .catch(function(e) {\n",
              "    console.error('getUserMedia error:', e);\n",
              "  });\n",
              "\n",
              "// recordButton.innerText = \"Press to start recording\";\n",
              "\n",
              "var data = new Promise(resolve => {\n",
              "  recordButton.onclick = function() {\n",
              "    if (!isRecording) {\n",
              "      // Memulai rekaman\n",
              "      recorder.start();\n",
              "      isRecording = true;\n",
              "      // recordButton.innerText = \"Recording... press to stop\";\n",
              "    } else {\n",
              "      // Menghentikan rekaman\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      isRecording = false;\n",
              "      // recordButton.innerText = \"Recording finished\";\n",
              "      // Resolusi dijalankan di recorder.onstop\n",
              "    }\n",
              "  };\n",
              "});\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Library Version"
      ],
      "metadata": {
        "id": "PmlYjkY5XMfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pkg_resources\n",
        "import torch\n",
        "import os\n",
        "import platform\n",
        "\n",
        "# List of libraries you want to check versions for\n",
        "libraries = [\n",
        "    'unsloth', 'xformers', 'trl', 'peft', 'accelerate', 'bitsandbytes',\n",
        "    'torchaudio', 'omegaconf', 'ffmpeg-python', 'assemblyai', 'PyAudio',\n",
        "    'googletrans', 'SpeechRecognition', 'gtts'\n",
        "]\n",
        "\n",
        "# Print library versions\n",
        "print(\"Library versions:\")\n",
        "for lib in libraries:\n",
        "    try:\n",
        "        version = pkg_resources.get_distribution(lib).version\n",
        "        print(f'{lib}: {version}')\n",
        "    except pkg_resources.DistributionNotFound:\n",
        "        print(f'{lib} is not installed')\n",
        "\n",
        "# Print CUDA version\n",
        "if torch.cuda.is_available():\n",
        "    print(f'\\nCUDA Version: {torch.version.cuda}')\n",
        "else:\n",
        "    print('\\nCUDA Version: Not available')\n",
        "\n",
        "# GPU information\n",
        "if torch.cuda.is_available():\n",
        "    print(f'\\nGPU: {torch.cuda.get_device_name(0)}')\n",
        "else:\n",
        "    print('\\nGPU: Not available')\n",
        "\n",
        "# Print OS and GPU information\n",
        "print(f'\\nOperating System: {platform.system()} {platform.release()}')\n",
        "print(f'Platform: {platform.platform()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN3D-wIRXJPS",
        "outputId": "2435bd2f-deba-4122-c5d0-5e83b23e7729"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Library versions:\n",
            "unsloth: 2024.8\n",
            "xformers: 0.0.27.post2\n",
            "trl: 0.8.6\n",
            "peft: 0.12.0\n",
            "accelerate: 0.33.0\n",
            "bitsandbytes: 0.43.3\n",
            "torchaudio: 2.4.0+cu121\n",
            "omegaconf: 2.3.0\n",
            "ffmpeg-python: 0.2.0\n",
            "assemblyai: 0.33.0\n",
            "PyAudio is not installed\n",
            "googletrans: 3.1.0a0\n",
            "SpeechRecognition: 3.10.4\n",
            "gtts: 2.5.3\n",
            "\n",
            "CUDA Version: 12.1\n",
            "\n",
            "GPU: Tesla T4\n",
            "\n",
            "Operating System: Linux 6.1.85+\n",
            "Platform: Linux-6.1.85+-x86_64-with-glibc2.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2\n",
        "\n",
        "////////// Text to speech"
      ],
      "metadata": {
        "id": "QhIFHW5ZG9nu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from huggingface_hub import login\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import Audio, display\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=128,\n",
        "        top_k=50,\n",
        "        temperature=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and print response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.split(\"### Response:\")[1].strip()\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "    while True:\n",
        "        user_input = input(\"Enter your question (or type 'back' to menu): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"bye\")\n",
        "            sys.exit(0)\n",
        "        elif user_input.lower() == 'back':\n",
        "            clear_output()\n",
        "            main()\n",
        "        else:\n",
        "            response = generate_response(user_input)\n",
        "            print(f\"Response: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "    while True:\n",
        "        user_input = input(\"Enter your question (or type 'back' to menu): \")\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"bye\")\n",
        "            sys.exit(0)\n",
        "        elif user_input.lower() == 'back':\n",
        "            clear_output()\n",
        "            main()\n",
        "        else:\n",
        "            response = generate_response(user_input)\n",
        "            generate_speech(response)\n",
        "            print(f\"Response: {response}\\n\")\n",
        "            time.sleep(3)\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text not implemented yet.\")\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech not implemented yet.\")\n",
        "        elif menu_select == 5:\n",
        "            print(\"Bye\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Dtouh9_tHJCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.1\n",
        "\n",
        "///////////// Speech to text and speech to speech"
      ],
      "metadata": {
        "id": "96iykBEyeUGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import numpy as np\n",
        "import assemblyai as aai\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(2)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def generate_text_from_speech():\n",
        "  aai.settings.api_key = \"e837d4ed54564d169547b812fa6153a1\"\n",
        "  language = 'en'\n",
        "  FILE_URL = \"output.wav\"\n",
        "  config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "  transcriber = aai.Transcriber()\n",
        "  transcript = transcriber.transcribe(\n",
        "    FILE_URL,\n",
        "    config=config\n",
        "  )\n",
        "\n",
        "  return transcript.text\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=128,\n",
        "        top_k=50,\n",
        "        temperature=1,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Decode and print response\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    response = response.split(\"### Response:\")[1].strip()\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    while True:\n",
        "        get_audio()\n",
        "        speech = generate_text_from_speech()\n",
        "\n",
        "        if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting program...\")\n",
        "          time.sleep(1)\n",
        "          sys.exit(0)\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting to menu...\")\n",
        "          time.sleep(1)\n",
        "          main()\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Me: {speech}\")\n",
        "        response = generate_response(speech)\n",
        "        print(f\"Tildha: {response}\")\n",
        "        print(\"\")\n",
        "        time.sleep(3)\n",
        "\n",
        "\n",
        "def speech_to_speech():\n",
        "  while True:\n",
        "    get_audio()\n",
        "    speech = generate_text_from_speech()\n",
        "\n",
        "    if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting program...\")\n",
        "      time.sleep(1)\n",
        "      sys.exit(0)\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting to menu...\")\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, opening command...\")\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "      print(\"\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Me: {speech}\")\n",
        "    response = generate_response(speech)\n",
        "    generate_speech(response)\n",
        "    print(f\"Tildha: {response}\")\n",
        "    print(\"\")\n",
        "    time.sleep(3)\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "88DuUQuaeU62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 687,
          "referenced_widgets": [
            "8c40fb079b474f4ab6fb3ec97f895225",
            "7f40f50c77c0443ba8b736fb883e819b",
            "7571c2a00d074a53a2a262ee03ef3297",
            "7cb31b92fd5648cf9cccdf557a5db23c",
            "c17885ef4c2b431d855bd21e618c5f33",
            "8ce17af533934a2791ffba775f1f4634",
            "9f40c5be55db484082896f1795fb234a",
            "81c8dc8ba7064c6ca170a3fee9c38a98",
            "29470ecc9e51410bbbe113d7d243ddc0",
            "0398ff75fd71482a8bb58f8bf26f06ed",
            "b072cf01c6624d449b53325e59fcc5a9",
            "56d337ddedad45e68ef247aa4f033a50",
            "2ad24b40496342e290aa590981d8e5ef",
            "dc4875e56a014c169942c16a34324c43",
            "eb13b1042c504bb98274065b109ac18a",
            "8d0e421834fc487496e681335b135311",
            "facd4fea95b24db6bad460d4a6a4d2b2",
            "365b6def49624d01b043790194c201ee",
            "a549c2366e224a8d9ee163ed310628a2",
            "6b28c6a27ffd40dc934f77a000959cbc",
            "5022462078674a3686da1726f085bf23",
            "d889d4b5cfa641c3a41ffb624ef382dd",
            "9abbf60e2dd24de3be92b0adc779dc36",
            "9cccb38a8e1f42499294e5cd081787e4",
            "8b5aa7d72e9849fab07e990b53a5d833",
            "58e894752b2240dcbc78abef524c2c8a",
            "c32d89af36fe4c1989e7047db0a95150",
            "0ee0762273634f7a88ebf9f3b709a306",
            "f6fdd09e57be4fe5853e52580f74c4be",
            "6e6a6e18383247fd84a90b0eb2df4307",
            "6a5ab215aa0a40b59ca9613e513deb90",
            "d7e41c5af84a4f74a3ec4f5e4296f84a",
            "cd02cb8e2bde4fd68e545ee90b917325",
            "60fed79d7d784d4a876ef7c259c2fb9c",
            "412c3dafd3a24a85b554aaa7630d1693",
            "3571bf3a91674346815b44b36690cff8",
            "816519a9f7e345d688e0ed0e5e44e881",
            "619ab716b7da4d08bcb2c3ef3d4f5b21",
            "ef674bb6780b4cd9b45fbe8efa1f56ab",
            "b164d5fea177469ebd5b3c917141388a",
            "44897e2f0b824dfbbf6818ae1c9dd62b",
            "b4e5660b138141ffb5d05fe8271aa041",
            "e9953eea384e4e2682d31878c881da44",
            "2e606008b82e475a9d16b6845b94780a",
            "7e768c84a5214f2fb1fd02fe55402c76",
            "302556d073d447feb2c8972fff7a43f1",
            "691b0dde075e494fa1760df1644ee6a6",
            "6c2b659e03064deb8453a3ba4cc35138",
            "9ad50b4ddff4435093f72870cfc35e29",
            "7922ac6f15744a5892e81cc619d5f8d2",
            "1f7d8eb3e0cf4cf7a5caa055411bef95",
            "d6b0b3ab630645eda16fc1275e2c28a0",
            "eea94f7ea93c43d781e71f900eb7e6bf",
            "b583adf31fc1444db69a5c8a77d4fa9b",
            "5d22596243a54e648e08a648726f51a1",
            "67ef37653cb3402798b1b2d3174b9421",
            "b78437ac4bec418c9b2a40233bfffd80",
            "d5d8fb2be29a47a2a7eebb2fc1b4a6c4",
            "af2f00c61abd439e8cb3c7813e19c7b7",
            "b68acbfaece149eeab06485443f90d40",
            "20cd8b4b0d2b4554b228cef1f3e8ffe5",
            "7c750f6319554f07a8c655771b85191c",
            "60b03618f89e475e990c2835a802e678",
            "194478937e384ecd85c3ec4b927465f1",
            "3e873d94f5534ba69eb693fae545adde",
            "002fe0b5cdab4fd4b3b77affd52c33e9",
            "9a23b5c216614aefaa79c73876ab0503",
            "c71db8226a32416a8b14e92f36393e47",
            "769ca1d645f64f4abfd5527e721e2c64",
            "0be7b07c6b2f4752a0981e703394f5dd",
            "cad5b1f4e27e448ab8811268ebe8aa6c",
            "6a0a5c40c4cf4a799e54a6b3b0b3fec0",
            "09fc1bd94f0e43a789d1f87e0bb49aba",
            "423e3efe774f4bdb9e739873284c085e",
            "53316abb0eb94886b768adb30a35dc19",
            "d188121d68864b4f8fd711d7774e8487",
            "1ca2f2dc742c4c2aa4243334d58dc738"
          ]
        },
        "outputId": "7371c39a-3fc3-4403-ad6e-79e390e7f20b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c40fb079b474f4ab6fb3ec97f895225"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56d337ddedad45e68ef247aa4f033a50"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/464 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9abbf60e2dd24de3be92b0adc779dc36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60fed79d7d784d4a876ef7c259c2fb9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "adapter_config.json:   0%|          | 0.00/732 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7e768c84a5214f2fb1fd02fe55402c76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67ef37653cb3402798b1b2d3174b9421"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9a23b5c216614aefaa79c73876ab0503"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-5a4b47923dbc>\u001b[0m in \u001b[0;36m<cell line: 153>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtranscript\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;34m\"Lvyn/AI-Tildha-Merged\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3548\u001b[0m                         \u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcommit_hash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3549\u001b[0m                     }\n\u001b[0;32m-> 3550\u001b[0;31m                     \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcached_file_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3552\u001b[0m                     \u001b[0;31m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"\\n\\n\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcustom_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1238\u001b[0m         )\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mWeakFileLock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlock_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         _download_to_tmp_and_move(\n\u001b[0m\u001b[1;32m   1390\u001b[0m             \u001b[0mincomplete_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".incomplete\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m             \u001b[0mdestination_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1913\u001b[0m             \u001b[0m_check_disk_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1915\u001b[0;31m         http_get(\n\u001b[0m\u001b[1;32m   1916\u001b[0m             \u001b[0murl_to_download\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0mnew_resume_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresume_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDOWNLOAD_CHUNK_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stream\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                     \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mChunkedEncodingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    934\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    877\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decoded_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0mflush_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_raw_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_catcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                 \u001b[0;31m# Platform-specific: Buggy versions of Python.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/urllib3/response.py\u001b[0m in \u001b[0;36m_fp_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# StringIO doesn't like amt=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     def _raw_read(\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 \u001b[0;31m# clip the read to the \"end of response\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m                 \u001b[0mamt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mamt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.2\n",
        "\n",
        "////////////// Fix major bug"
      ],
      "metadata": {
        "id": "G9Zg0kn97Tm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import numpy as np\n",
        "import assemblyai as aai\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(2)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def generate_text_from_speech():\n",
        "  aai.settings.api_key = \"e837d4ed54564d169547b812fa6153a1\"\n",
        "  language = 'en'\n",
        "  FILE_URL = \"output.wav\"\n",
        "  config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "  transcriber = aai.Transcriber()\n",
        "  transcript = transcriber.transcribe(\n",
        "    FILE_URL,\n",
        "    config=config\n",
        "  )\n",
        "\n",
        "  return transcript.text\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    while True:\n",
        "        get_audio()\n",
        "        speech = generate_text_from_speech()\n",
        "\n",
        "        if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting program...\")\n",
        "          time.sleep(1)\n",
        "          sys.exit(0)\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting to menu...\")\n",
        "          time.sleep(1)\n",
        "          main()\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Me: {speech}\")\n",
        "        response = generate_response(speech)\n",
        "        print(f\"Tildha: {response}\")\n",
        "        print(\"\")\n",
        "        time.sleep(3)\n",
        "\n",
        "\n",
        "def speech_to_speech():\n",
        "  while True:\n",
        "    get_audio()\n",
        "    speech = generate_text_from_speech()\n",
        "\n",
        "    if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting program...\")\n",
        "      time.sleep(1)\n",
        "      sys.exit(0)\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting to menu...\")\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, opening command...\")\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "      print(\"\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Me: {speech}\")\n",
        "    response = generate_response(speech)\n",
        "    generate_speech(response)\n",
        "    print(f\"Tildha: {response}\")\n",
        "    print(\"\")\n",
        "    time.sleep(3)\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "HxZkCNqj7RLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.3\n",
        "\n",
        "////////////// identity added"
      ],
      "metadata": {
        "id": "fLz1e6qiRw_W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import numpy as np\n",
        "import assemblyai as aai\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(2)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def generate_text_from_speech():\n",
        "  aai.settings.api_key = \"e837d4ed54564d169547b812fa6153a1\"\n",
        "  language = 'en'\n",
        "  FILE_URL = \"output.wav\"\n",
        "  config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "  transcriber = aai.Transcriber()\n",
        "  transcript = transcriber.transcribe(\n",
        "    FILE_URL,\n",
        "    config=config\n",
        "  )\n",
        "\n",
        "  return transcript.text\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    while True:\n",
        "        get_audio()\n",
        "        speech = generate_text_from_speech()\n",
        "\n",
        "        if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting program...\")\n",
        "          time.sleep(1)\n",
        "          sys.exit(0)\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting to menu...\")\n",
        "          time.sleep(1)\n",
        "          main()\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Me: {speech}\")\n",
        "        response = generate_response(speech)\n",
        "        print(f\"Tildha: {response}\")\n",
        "        print(\"\")\n",
        "        time.sleep(3)\n",
        "\n",
        "\n",
        "def speech_to_speech():\n",
        "  while True:\n",
        "    get_audio()\n",
        "    speech = generate_text_from_speech()\n",
        "\n",
        "    if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting program...\")\n",
        "      time.sleep(1)\n",
        "      sys.exit(0)\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting to menu...\")\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, opening command...\")\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "      print(\"\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Me: {speech}\")\n",
        "    response = generate_response(speech)\n",
        "    generate_speech(response)\n",
        "    print(f\"Tildha: {response}\")\n",
        "    print(\"\")\n",
        "    time.sleep(3)\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "Dgd-PCwnRtoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.4\n",
        "\n",
        "//////////// text to text multilanguage support"
      ],
      "metadata": {
        "id": "2bKvVe5ZpeQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "import numpy as np\n",
        "import assemblyai as aai\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(2)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def generate_text_from_speech():\n",
        "  aai.settings.api_key = \"e837d4ed54564d169547b812fa6153a1\"\n",
        "  language = 'en'\n",
        "  FILE_URL = \"output.wav\"\n",
        "  config = aai.TranscriptionConfig(speaker_labels=True)\n",
        "  transcriber = aai.Transcriber()\n",
        "  transcript = transcriber.transcribe(\n",
        "    FILE_URL,\n",
        "    config=config\n",
        "  )\n",
        "\n",
        "  return transcript.text\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    while True:\n",
        "        get_audio()\n",
        "        speech = generate_text_from_speech()\n",
        "\n",
        "        if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting program...\")\n",
        "          time.sleep(1)\n",
        "          sys.exit(0)\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting to menu...\")\n",
        "          time.sleep(1)\n",
        "          main()\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Me: {speech}\")\n",
        "        response = generate_response(speech)\n",
        "        print(f\"Tildha: {response}\")\n",
        "        print(\"\")\n",
        "        time.sleep(3)\n",
        "\n",
        "\n",
        "def speech_to_speech():\n",
        "  while True:\n",
        "    get_audio()\n",
        "    speech = generate_text_from_speech()\n",
        "\n",
        "    if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting program...\")\n",
        "      time.sleep(1)\n",
        "      sys.exit(0)\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting to menu...\")\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, opening command...\")\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "      print(\"\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Me: {speech}\")\n",
        "    response = generate_response(speech)\n",
        "    generate_speech(response)\n",
        "    print(f\"Tildha: {response}\")\n",
        "    print(\"\")\n",
        "    time.sleep(3)\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "WYgfnG1_oRb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.5\n",
        "\n",
        "/////////// Fix speech system"
      ],
      "metadata": {
        "id": "KezM_fPQZUUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def generate_text_from_speech():\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-5\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    while True:\n",
        "        get_audio()\n",
        "        speech = generate_text_from_speech()\n",
        "\n",
        "        if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting program...\")\n",
        "          time.sleep(1)\n",
        "          sys.exit(0)\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "          print(f\"Me: {speech}\")\n",
        "          print(\"Tildha: okay, exiting to menu...\")\n",
        "          time.sleep(1)\n",
        "          main()\n",
        "\n",
        "        elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Me: {speech}\")\n",
        "        response = generate_response(speech)\n",
        "        print(f\"Tildha: {response}\")\n",
        "        print(\"\")\n",
        "        time.sleep(3)\n",
        "\n",
        "\n",
        "def speech_to_speech():\n",
        "  while True:\n",
        "    get_audio()\n",
        "    speech = generate_text_from_speech()\n",
        "\n",
        "    if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting program...\")\n",
        "      time.sleep(1)\n",
        "      sys.exit(0)\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, exiting to menu...\")\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "\n",
        "    elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "      print(f\"Me: {speech}\")\n",
        "      print(\"Tildha: okay, opening command...\")\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "      print(\"\")\n",
        "      continue\n",
        "\n",
        "    print(f\"Me: {speech}\")\n",
        "    response = generate_response(speech)\n",
        "    generate_speech(response)\n",
        "    print(f\"Tildha: {response}\")\n",
        "    print(\"\")\n",
        "    time.sleep(3)\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "7zoVPvN6Zca-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.6\n",
        "\n",
        "//////////// Support Indonesian and English speech language"
      ],
      "metadata": {
        "id": "o8EM3pvlJkVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=128, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       lang = detect_lang(user_input)\n",
        "       response = translate(lang, response)\n",
        "       generate_speech(response)\n",
        "       print(f\"Tildha: {response}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          lang = detect_lang(user_input)\n",
        "          response = translate(lang, response)\n",
        "          print(f\"Tildha: {response}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          lang = detect_lang(user_input)\n",
        "          response = translate(lang, response)\n",
        "          generate_speech(response)\n",
        "          print(f\"Tildha: {response}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "NcvsozB_Jkq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.7\n",
        "\n",
        "/////// add new Indonesian speech engine"
      ],
      "metadata": {
        "id": "zZxrCyFxgl39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=64, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  print(\"\")\n",
        "  display(Audio(audio, rate=48000, autoplay=True))\n",
        "  print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       id_lang = detect_lang(user_input)\n",
        "       responses = translate(id_lang, response)\n",
        "       if id_lang == \"indonesian\" :\n",
        "          generate_indonesian_speech(responses)\n",
        "       else :\n",
        "          generate_speech(responses)\n",
        "       print(f\"Tildha: {responses}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "1wKlgOq-gjNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.8\n",
        "\n",
        "////////// Format return response"
      ],
      "metadata": {
        "id": "yJCulC2zjeuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  print(\"\")\n",
        "  display(Audio(audio, rate=48000, autoplay=True))\n",
        "  print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       id_lang = detect_lang(user_input)\n",
        "       responses = translate(id_lang, response)\n",
        "       if id_lang == \"indonesian\" :\n",
        "          generate_indonesian_speech(responses)\n",
        "       else :\n",
        "          generate_speech(responses)\n",
        "       print(f\"Tildha: {responses}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "ykxZfh53jlKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.9\n",
        "\n",
        "////////// Fix audio buffer"
      ],
      "metadata": {
        "id": "7Q7--RBINMW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(2)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  print(\"\")\n",
        "  display(Audio(audio, rate=48000, autoplay=True))\n",
        "  print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      clear_output()\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "       clear_output()\n",
        "       main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       clear_output()\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       id_lang = detect_lang(user_input)\n",
        "       responses = translate(id_lang, response)\n",
        "       if id_lang == \"indonesian\" :\n",
        "          generate_indonesian_speech(responses)\n",
        "       else :\n",
        "          generate_speech(responses)\n",
        "       print(f\"Tildha: {responses}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    clear_output()\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        clear_output()\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2EYNRH9WNasv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2.10\n",
        "\n",
        "///////////Fix audio channel & fix race condition clear output"
      ],
      "metadata": {
        "id": "pT80K2NYO6cx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, Audio, clear_output, display\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from huggingface_hub import login\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "from googletrans import Translator, LANGUAGES\n",
        "from gtts import gTTS\n",
        "import speech_recognition as sr\n",
        "import assemblyai as aai\n",
        "import numpy as np\n",
        "import io\n",
        "import wave\n",
        "import subprocess\n",
        "import ffmpeg\n",
        "import time\n",
        "import torch\n",
        "import sys\n",
        "import torch\n",
        "import threading\n",
        "import warnings\n",
        "import logging\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Log in Hugging Face\n",
        "login(\"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\")\n",
        "\n",
        "# Load tokenizer and model with optimizations\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Lvyn/AI-Tildha-Merged\")\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = \"\";  // Mengubah inisialisasi base64data menjadi string kosong\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "var isRecording = false;  // Variable untuk melacak status rekaman\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = false;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "};\n",
        "\n",
        "recordButton.innerText = \"Press to start recording\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess).catch(function(e) {\n",
        "  console.error('getUserMedia error:', e);\n",
        "});\n",
        "\n",
        "var data = new Promise(resolve => {\n",
        "  recordButton.onclick = function() {\n",
        "    if (!isRecording) {\n",
        "      // Memulai rekaman\n",
        "      recorder.start();\n",
        "      isRecording = true;\n",
        "      recordButton.innerText = \"Recording... press to stop\";\n",
        "    } else {\n",
        "      // Menghentikan rekaman\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      isRecording = false;\n",
        "      recordButton.style.display = 'none'; // Mengatur tombol menjadi tidak terlihat\n",
        "      // Tunggu 2000ms untuk data tersedia\n",
        "      sleep(2000).then(() => {\n",
        "        resolve(base64data.toString());\n",
        "      });\n",
        "    }\n",
        "  };\n",
        "});\n",
        "\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  with wave.open('output.wav', 'wb') as wav_file:\n",
        "    wav_file.setnchannels(1)\n",
        "    wav_file.setsampwidth(2)\n",
        "    wav_file.setframerate(48000)\n",
        "    wav_file.writeframes(audio)\n",
        "\n",
        "  return audio, sr\n",
        "\n",
        "\n",
        "def lang_menu():\n",
        "  print(\"\"\"\n",
        "Select speech language\n",
        "1. Speech Indonesian\n",
        "2. Speech English\n",
        "3. Back\n",
        "    \"\"\")\n",
        "  try:\n",
        "    opsi = int(input(\"Select mode (1/2/3): \"))\n",
        "    print(\"\")\n",
        "    return opsi\n",
        "  except ValueError as e:\n",
        "    pass\n",
        "    print(\"\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"\\nOperation canceled by user. Exiting...\")\n",
        "    sys.exit(0)\n",
        "\n",
        "def generate_text_from_speech(lang):\n",
        "  r = sr.Recognizer()\n",
        "  hellow = sr.AudioFile('output.wav')\n",
        "  with hellow as source:\n",
        "      audio = r.record(source)\n",
        "  try:\n",
        "      s = r.recognize_google(audio, language=lang)\n",
        "      return s\n",
        "  except Exception as e:\n",
        "      print(\"Exception: \"+str(e))\n",
        "\n",
        "def translate(bahasa, text):\n",
        "  translator = Translator()\n",
        "  translate = translator.translate(text, dest = bahasa)\n",
        "  return translate.text\n",
        "\n",
        "def detect_lang(inputan):\n",
        "  translator = Translator()\n",
        "  kalimat = inputan\n",
        "  detection = translator.detect(kalimat)\n",
        "  return LANGUAGES[detection.lang]\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Lvyn/AI-Tildha-Merged\",\n",
        "    torch_dtype=torch.float16,\n",
        "    low_cpu_mem_usage=True  # Reduce CPU memory usage\n",
        ")\n",
        "\n",
        "tildha_prompt = \"\"\"Based on the data you have studied, Your name is Tildha and you are an AI Healthcare Assistant. Below are the questions users have asked you. Write a response that answers the question appropriately. Answer based on the data you have studied\n",
        "\n",
        "### Request:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    requests = examples[\"request\"]\n",
        "    responses = examples[\"response\"]\n",
        "    texts = []\n",
        "    for request, response in zip(requests, responses):\n",
        "        text = tildha_prompt.format(request, response) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts }\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(\n",
        "        tildha_prompt.format(prompt, \"\"), return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    # Model parameters\n",
        "    # Decode and print response\n",
        "    outputs = model.generate(**inputs, max_new_tokens=500, use_cache=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    # Process decoded_outputs\n",
        "    response = \"\"\n",
        "    for output in decoded_outputs:\n",
        "        if \"### Response:\" in output:\n",
        "            response = output.split(\"### Response:\")[1].strip()\n",
        "            break\n",
        "    return response.split(\"###\")[0].strip()\n",
        "\n",
        "def generate_speech(response):\n",
        "    language = 'en'\n",
        "    model_id = 'v3_en'\n",
        "    sample_rate = 48000\n",
        "    speaker = 'en_107'\n",
        "    device = torch.device('cuda')\n",
        "\n",
        "    model, example_text = torch.hub.load(repo_or_dir='snakers4/silero-models',\n",
        "                                        model='silero_tts',\n",
        "                                        language=language,\n",
        "                                        speaker=model_id)\n",
        "    model.to(device)  # gpu or cpu\n",
        "\n",
        "    audio = model.apply_tts(text=response,\n",
        "                            speaker=speaker,\n",
        "                            sample_rate=sample_rate)\n",
        "    print(\"\")\n",
        "    display(Audio(audio, rate=sample_rate, autoplay=True))\n",
        "    print(\"\")\n",
        "\n",
        "def generate_indonesian_speech(text):\n",
        "  bahasa = \"id\"\n",
        "  file = gTTS(text = text, lang=bahasa)\n",
        "  file.save(\"speech.wav\")\n",
        "\n",
        "  with open(\"speech.wav\", 'rb') as f :\n",
        "    audio = f.read()\n",
        "\n",
        "  print(\"\")\n",
        "  display(Audio(audio, rate=48000, autoplay=True))\n",
        "  print(\"\")\n",
        "\n",
        "def menu():\n",
        "    print(\"\"\"\n",
        "Select mode Tildha AI\n",
        "1. Text to text\n",
        "2. Text to speech\n",
        "3. Speech to text\n",
        "4. Speech to speech\n",
        "5. Command shortcut\n",
        "6. Exit\n",
        "    \"\"\")\n",
        "    try:\n",
        "        menu_select = int(input(\"Select mode (1/2/3/4/5/6): \"))\n",
        "        return menu_select\n",
        "    except ValueError as e:\n",
        "        print(\"Invalid input! Select range 1-6\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nOperation canceled by user. Exiting...\")\n",
        "        quit()\n",
        "\n",
        "def text_to_text():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye.....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "       time.sleep(1)\n",
        "       help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "      response = generate_response(user_input)\n",
        "      lang = detect_lang(user_input)\n",
        "      response = translate(lang, response)\n",
        "      print(f\"Tildha: {response}\\n\")\n",
        "\n",
        "def text_to_speech():\n",
        "  while True:\n",
        "    user_input = input(\"Me: \")\n",
        "    if user_input.lower() == '!exit':\n",
        "      print(\"Tildha: okey, bye....\")\n",
        "      sys.exit(0)\n",
        "    elif user_input.lower() == '!menu':\n",
        "      time.sleep(1)\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      main()\n",
        "    elif user_input.lower() == '!help':\n",
        "      time.sleep(1)\n",
        "      clear_output()\n",
        "      time.sleep(1)\n",
        "      help()\n",
        "    elif user_input.startswith('!'):\n",
        "       print(\"Tildha: Sorry, I didn't understand that command. Type !help for available commands.\")\n",
        "       print(\"\")\n",
        "    else:\n",
        "       response = generate_response(user_input)\n",
        "       id_lang = detect_lang(user_input)\n",
        "       responses = translate(id_lang, response)\n",
        "       if id_lang == \"indonesian\" :\n",
        "          generate_indonesian_speech(responses)\n",
        "       else :\n",
        "          generate_speech(responses)\n",
        "       print(f\"Tildha: {responses}\\n\")\n",
        "       time.sleep(3)\n",
        "\n",
        "def speech_to_text():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def speech_to_speech():\n",
        "    lang = lang_menu()\n",
        "    if lang == 1 or lang == 2:\n",
        "      while True:\n",
        "          get_audio()\n",
        "          if lang == 1:\n",
        "            speech = generate_text_from_speech(\"id-ID\")\n",
        "          elif lang == 2:\n",
        "            speech = generate_text_from_speech(\"en-EN\")\n",
        "\n",
        "          if \"hey\" in speech.lower() and \"please\" in speech.lower() and \"exit\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"keluar\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar dari program...\")\n",
        "            time.sleep(1)\n",
        "            sys.exit(0)\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, exiting to menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"menu\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, keluar ke menu...\")\n",
        "            time.sleep(1)\n",
        "            main()\n",
        "\n",
        "          elif \"hey\" in speech.lower() and \"please\" in speech.lower() and \"help\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: okay, opening command...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          elif \"hei\" in speech.lower() and \"tolong\" in speech.lower() and \"bantuan\" in speech.lower():\n",
        "            print(f\"Me: {speech}\")\n",
        "            print(\"Tildha: oke, menampilkan perintah bantuan...\")\n",
        "            time.sleep(1)\n",
        "            help()\n",
        "            print(\"\")\n",
        "            continue\n",
        "\n",
        "          print(f\"Me: {speech}\")\n",
        "          response = generate_response(speech)\n",
        "          id_lang = detect_lang(speech)\n",
        "          responses = translate(id_lang, response)\n",
        "          if id_lang == \"indonesian\" :\n",
        "            generate_indonesian_speech(responses)\n",
        "          else :\n",
        "            generate_speech(responses)\n",
        "          print(f\"Tildha: {responses}\")\n",
        "          print(\"\")\n",
        "          time.sleep(3)\n",
        "    elif lang == 3:\n",
        "      main()\n",
        "    else:\n",
        "      print(\"Invalid input! Select range 1-3\")\n",
        "      speech_to_text()\n",
        "\n",
        "def help():\n",
        "  print(\"\"\"\n",
        "Text command:\n",
        "back to menu = !menu\n",
        "exit program = !exit\n",
        "show command = !help\n",
        "\n",
        "Voice command:\n",
        "back to menu = hey please menu\n",
        "exit program = hey please exit\n",
        "show command = hey please help\n",
        "  \"\"\")\n",
        "\n",
        "# program utama\n",
        "def main():\n",
        "    time.sleep(1)\n",
        "    clear_output()\n",
        "    time.sleep(1)\n",
        "    while True:\n",
        "        menu_select = menu()\n",
        "        time.sleep(1)\n",
        "        clear_output()\n",
        "        time.sleep(1)\n",
        "        if menu_select == 1:\n",
        "            print(\"Text to text\\n\")\n",
        "            text_to_text()\n",
        "        elif menu_select == 2:\n",
        "            print(\"Text to speech\\n\")\n",
        "            text_to_speech()\n",
        "        elif menu_select == 3:\n",
        "            print(\"Speech to text\\n\")\n",
        "            speech_to_text()\n",
        "        elif menu_select == 4:\n",
        "            print(\"Speech to speech\\n\")\n",
        "            speech_to_speech()\n",
        "        elif menu_select == 5:\n",
        "            help()\n",
        "        elif menu_select == 6:\n",
        "            print(\"Tildha: see you...\")\n",
        "            sys.exit(0)\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid input! Select range 1-5\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "sIF2WW9kPDJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516,
          "referenced_widgets": [
            "2c8efe2d7e234d7c81183505a22e3ff0",
            "a4cf4409c1d649178dc8785c49c8daae",
            "78e6ec68b2b640f59423e5ca363df4d0",
            "05d6acf887e241439550a86db81d5249",
            "d030dc02986546308e1f99f6d195178b",
            "2b35d00d22e14d6a80cd58ce8d26d613",
            "8156029018544159b350f115a7da7ccd",
            "749400df9a3f46de92cbf5a9d6ed7a5f",
            "53902e5b0b1748ed881507266c4179f7",
            "4237a7ae3ee2419c93a716144417113d",
            "0f3c348263c7442295857ed17cda82d5",
            "711aa5e856eb41f09be8e95788edf8da",
            "d5467a9b8c774c95b2251ecf5919a05c",
            "8252eb77c9764991902e5a3fb60e1010",
            "9e8543ac73f243a8b7fed93b9182e092",
            "53d618fcc7dd432dbff4052f3fd0250c",
            "4e98e63e603045978bd04df142eedd4e",
            "f4163b78e53e475fbda2d9bad59a2b91",
            "5bf55e4971394a7697514dd42f36de8a",
            "c7b874afe03146f294f54355c2201355",
            "a0a0d595534a4899917e64b04f6f19ec",
            "24dfd324334a49589403fb8f6aaf6f53",
            "384fc31be552481c94814fab1f9da8f1",
            "7e39e30316dd46599479a64a7d194893",
            "d871211a8838424498669729db35abb1",
            "16434a12a88f487a8aed1e3dd1214150",
            "fba430b9ac1349edbbc6894d1406bf35",
            "1e4024cffed142dc805883e71a5b419b",
            "fd5dfb7750be4ebba5305bfaa6b9cadd",
            "d60ecf5035134f32851fb472723d9d9a",
            "51f1231786a44f26a6cf01b015cdcf8a",
            "911df9b3e7a04ee1abc82a7ad015c399",
            "a03daf5a91f3470d8a6552f1dd9ab1af"
          ]
        },
        "outputId": "66bb100d-0d9d-41d9-b1e2-7e3193143175"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Speech to text\n",
            "\n",
            "\n",
            "Select speech language\n",
            "1. Speech Indonesian\n",
            "2. Speech English\n",
            "3. Back\n",
            "    \n",
            "Select mode (1/2/3): 1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "var my_div = document.createElement(\"DIV\");\n",
              "var my_btn = document.createElement(\"BUTTON\");\n",
              "var t = document.createTextNode(\"Press to start recording\");\n",
              "my_btn.appendChild(t);\n",
              "my_div.appendChild(my_btn);\n",
              "document.body.appendChild(my_div);\n",
              "\n",
              "var base64data = \"\";  // Inisialisasi base64data\n",
              "var recorder, gumStream;\n",
              "var recordButton = my_btn;\n",
              "var isRecording = false;  // Untuk melacak status rekaman\n",
              "\n",
              "// Fungsi yang dipanggil saat perekaman berhasil\n",
              "var handleSuccess = function(stream) {\n",
              "  gumStream = stream;\n",
              "  var options = {\n",
              "    mimeType: 'audio/webm;codecs=opus'\n",
              "  };\n",
              "  recorder = new MediaRecorder(stream);\n",
              "\n",
              "  recorder.ondataavailable = function(e) {\n",
              "    var reader = new FileReader();\n",
              "    reader.readAsDataURL(e.data);\n",
              "    reader.onloadend = function() {\n",
              "      base64data = reader.result;\n",
              "      console.log(\"Audio data in base64: \", base64data);\n",
              "    };\n",
              "  };\n",
              "\n",
              "  recorder.onstop = function() {\n",
              "    console.log(\"Recording stopped, data is ready\");\n",
              "    resolve(base64data);\n",
              "  };\n",
              "};\n",
              "\n",
              "navigator.mediaDevices.getUserMedia({audio: true})\n",
              "  .then(handleSuccess)\n",
              "  .catch(function(e) {\n",
              "    console.error('getUserMedia error:', e);\n",
              "  });\n",
              "\n",
              "recordButton.innerText = \"Press to start recording\";\n",
              "\n",
              "var data = new Promise(resolve => {\n",
              "  recordButton.onclick = function() {\n",
              "    if (!isRecording) {\n",
              "      // Memulai rekaman\n",
              "      recorder.start();\n",
              "      isRecording = true;\n",
              "      recordButton.innerText = \"Recording... press to stop\";\n",
              "    } else {\n",
              "      // Menghentikan rekaman\n",
              "      recorder.stop();\n",
              "      gumStream.getAudioTracks()[0].stop();\n",
              "      isRecording = false;\n",
              "      recordButton.innerText = \"Recording finished\";\n",
              "      // Resolusi dijalankan di recorder.onstop\n",
              "    }\n",
              "  };\n",
              "});\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-cccb488b9805>\u001b[0m in \u001b[0;36m<cell line: 489>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-27-cccb488b9805>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmenu_select\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Speech to text\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m             \u001b[0mspeech_to_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmenu_select\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Speech to speech\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-cccb488b9805>\u001b[0m in \u001b[0;36mspeech_to_text\u001b[0;34m()\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m           \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlang\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mspeech\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_text_from_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id-ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-cccb488b9805>\u001b[0m in \u001b[0;36mget_audio\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAUDIO_HTML\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_js\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m   \u001b[0mbinary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb64decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}